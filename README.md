# Clasificador Alzheimer TFG

Te explicar√© a continuaci√≥n todo lo que podr√°s encontrar en este repositorio y lo que necesitar√°s para el TFG.

## Contexto y carperta papers

Encontrar√°s dos papers sobre el algoritmo wav2vec2 y el modelo preentrenado XLSR-wav2vec2, y un tercer paper que explica lo que el algoritmo aprende en cada capa durante el entrenamiento. Nos basaremos en este √∫ltimo para extraer informaci√≥n de alguna capa intermedia y probar diferentes clasificadores. Tambi√©n hay un paper sobre lo que aprende el algoritmo en cada una de sus capas.

No pretendo que leas los papers al detalle, ya que contienen mucha informaci√≥n t√©cnica. La idea es que a partir de ellos busques informaci√≥n y preguntes cualquier duda que te surja. Por ejemplo, puedes preguntar qu√© significa que un algoritmo sea semi-supervisado, qu√© es un modelo preentrenado, qu√© son las transformers, etc. Tampoco hace falta profundizar mucho en la parte t√©cnica, ya que el enfoque del estudio son los clasificadores.

Utilizaremos el modelo preentrenado XLSR-wav2vec2, que es un modelo de lenguaje preentrenado con una gran cantidad de datos de habla multiling√ºe. Es capaz de aprender patrones ling√º√≠sticos entre diferentes idiomas y mejorar la calidad de la transcripci√≥n. En concreto, usaremos un modelo subido a https://huggingface.co/ (Hugging Face es una comunidad en la que las personas pueden compartir modelos de lenguaje preentrenados y tambi√©n proporcionan APIs para trabajar con ciertos algoritmos o redes neuronales). Dado que los audios de Alzheimer est√°n en ingl√©s, utilizaremos esta inferencia: https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english.

## Dataset 

El dataset se ha extra√≠do de [este challenge](https://luzs.gitlab.io/adresso-2021/) que se llev√≥ a cabo en 2021 para la conferencia internacional Interspeech. Los audios se han obtenido de [DementiaBank](https://dementia.talkbank.org/) una base de datos compartida que contiene videos y audios de pacientes con demencia (Alzheimer). En concreto, los datos se encuentran en la p√°gina del challenge: https://dementia.talkbank.org/ADReSS-2021/ . Para descargar los audios/videos de esta web, es necesario solicitar un usuario y contrase√±a.

En este repositorio, encontrar√°s un archivo CSV que es el dataframe con el que trabajar√°s en los clasificadores. Debido a que los audios son confidenciales y de car√°cter sensible, los compartir√© contigo por email.

## Pipeline

1) Procesamiento de los archivos de audio y csv
2) Fine-tuning con los datos de Alzheimer
3) Se selecciona previamente de que capa intermedia vamos a extraer los tensores para luego aplicarlos al clasificador. 
4) **Aplicar diferentes algoritmos de clasificacion para pacientes con Alzheimer y control**
5) **Optimizadores de hiperparametros para estos clasificadores**

Puntos 4) y 5) son los tuyos üòâ 

## Scripts de python y archivo csv

El m√°s importante para ti es el script clasificadores.py. El resto los he subido por si quieres tener m√°s contexto de donde saco los tensores que te pasar√© para los clasificadores. Te explico brevemente a continuaci√≥n: 

-  inferencia.py : hago una llamada al modelo subido a Hugging Face que coment√© anteriormente y extraigo los tensores de una capa intermedia espec√≠fica.
-  **clasificador.py: c√≥digo con c√≥mo leer tensores, dividir el conjunto de datos en entrenamiento y prueba, clasificador XGBoost y m√©tricas de puntuaci√≥n**
-  bayesianopt.py : peque√±o intento de un optimizador bayesiano sin usar la biblioteca Optuna porque me daba errores en el servidor. En este caso, te recomendar√≠a usar la biblioteca Optuna porque no me funcion√≥ correctamente. Te lo dejo por si te sirviera de algo.
-  gridsearch.py : XGBoost con un GridSearch para buscar mejores hiperpar√°metros. Tampoco fue muy eficaz por c√≥mo es el m√©todo en s√≠ de lento.

- df_filter.csv: DataFrame donde viene toda la informaci√≥n.


## Propuestas de clasificadores

Esto es orientativo, para nada hay que hacerlos todos y se pueden proponer otros que veamos mejores o m√°s interesantes. Seguramente, para una clasificaci√≥n binaria, muchos no sean los mejores, iremos analiz√°ndolo.

- XGBoost
- LightBoost
- CatBoost
- AdaBoost
- Logistic Regression
- SVM
- Red neuronal de 2 salidas
- Random forest 
